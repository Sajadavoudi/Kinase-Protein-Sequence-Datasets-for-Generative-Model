{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e884fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import ConvexHull\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275eb8ad",
   "metadata": {},
   "source": [
    "### Transformaer vae\n",
    "Encoder path: (263,21) → (263,64) → (64) → (32)\n",
    "Decoder path: (32) → (263,128) → (263,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7fdfcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------ Custom Layers ------\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Reparameterization trick layer\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config()\n",
    "\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    \"\"\"Positional encoding layer for transformer models.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        _, self.seq_length, self.d_model = input_shape\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        # Ensure the base is a float: 10000.0 instead of 10000.\n",
    "        angle_rates = 1 / tf.pow(tf.constant(10000.0, dtype=tf.float32), (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def call(self, x):\n",
    "        # x shape: (batch, seq_length, d_model)\n",
    "        # Create a tensor for positions: shape (seq_length, 1)\n",
    "        positions = tf.cast(tf.range(self.seq_length)[:, tf.newaxis], tf.float32)\n",
    "        # Create a tensor for the dimensions: shape (1, d_model)\n",
    "        dims = tf.cast(tf.range(self.d_model)[tf.newaxis, :], tf.float32)\n",
    "        angle_rads = self.get_angles(positions, dims, self.d_model)\n",
    "        \n",
    "        # Apply sin to even indices and cos to odd indices\n",
    "        sines = tf.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        # Concatenate along the last dimension. We need to interleave sin and cos.\n",
    "        # One way is to create a tensor of the same shape as angle_rads and fill\n",
    "        # even indices with sines and odd indices with cosines.\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[:, :self.d_model]  # Make sure the shape matches.\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]    # (1, seq_length, d_model)\n",
    "        \n",
    "        return x + pos_encoding\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        # Optionally include parameters like seq_length and d_model if needed.\n",
    "        config.update({\n",
    "            \"seq_length\": self.seq_length,\n",
    "            \"d_model\": self.d_model,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model//num_heads)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        attn_output = self.mha(query=x, key=x, value=x)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'd_model': self.mha.key_dim * self.mha.num_heads,\n",
    "            # You could add more parameters here if needed.\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# ------ Custom Transformer Encoder/Decoder ------\n",
    "class CustomTransformerEncoder(layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, seq_length, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.enc_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_layers': self.num_layers,\n",
    "            'd_model': self.d_model,\n",
    "            'seq_length': self.seq_length\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class CustomTransformerDecoder(layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, seq_length, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dec_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_layers': self.num_layers,\n",
    "            'd_model': self.d_model,\n",
    "            'seq_length': self.seq_length\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# ------ Transformer VAE Model ------\n",
    "class TransformerVAE(Model):\n",
    "    def __init__(self, seq_length=263, input_dim=21, latent_dim=32, num_heads=4, intermediate_dim=128, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seq_length = seq_length\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder: Add positional encoding, then transformer encoder blocks.\n",
    "        self.encoder_projection = layers.Dense(intermediate_dim)  # Project input_dim to intermediate_dim.\n",
    "        self.transformer_encoder = CustomTransformerEncoder(num_layers=2, d_model=intermediate_dim, \n",
    "                                                             num_heads=num_heads, dff=intermediate_dim*2,\n",
    "                                                             seq_length=seq_length, dropout_rate=0.1)\n",
    "        self.pool = layers.GlobalAveragePooling1D()\n",
    "        self.z_mean_dense = layers.Dense(latent_dim)\n",
    "        self.z_log_var_dense = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "        \n",
    "        # Decoder: Project latent back and reshape, followed by transformer decoder blocks.\n",
    "        self.decoder_projection = layers.Dense(seq_length * intermediate_dim, activation='relu')\n",
    "        self.decoder_reshape = layers.Reshape((seq_length, intermediate_dim))\n",
    "        self.transformer_decoder = CustomTransformerDecoder(num_layers=2, d_model=intermediate_dim, \n",
    "                                                             num_heads=num_heads, dff=intermediate_dim*2,\n",
    "                                                             seq_length=seq_length, dropout_rate=0.1)\n",
    "        self.decoder_output = layers.Dense(input_dim, activation='softmax')\n",
    "    \n",
    "    def encode(self, inputs, training=False):\n",
    "        # inputs shape: (batch, seq_length, input_dim)\n",
    "        x = self.encoder_projection(inputs)    # (batch, seq_length, intermediate_dim)\n",
    "        x = self.transformer_encoder(x, training=training)  # (batch, seq_length, intermediate_dim)\n",
    "        x = self.pool(x)                       # (batch, intermediate_dim)\n",
    "        z_mean = self.z_mean_dense(x)            # (batch, latent_dim)\n",
    "        z_log_var = self.z_log_var_dense(x)      # (batch, latent_dim)\n",
    "        return z_mean, z_log_var\n",
    "    \n",
    "    def decode(self, z, training=False):\n",
    "        x = self.decoder_projection(z)          # (batch, seq_length * intermediate_dim)\n",
    "        x = self.decoder_reshape(x)             # (batch, seq_length, intermediate_dim)\n",
    "        x = self.transformer_decoder(x, training=training)  # (batch, seq_length, intermediate_dim)\n",
    "        reconstruction = self.decoder_output(x) # (batch, seq_length, input_dim)\n",
    "        return reconstruction\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var = self.encode(inputs, training=training)\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        reconstruction = self.decode(z, training=training)\n",
    "        # Add KL divergence loss.\n",
    "        kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstruction\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"seq_length\": self.seq_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b591edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_vae_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer_vae_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">263</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_transformer_encoder_2    │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">264,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomTransformerEncoder</span>)      │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_6      │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sampling_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>)           │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33664</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,110,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">263</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_transformer_decoder_2    │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">264,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomTransformerDecoder</span>)      │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">263</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,709</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_77 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m263\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │         \u001b[38;5;34m2,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_transformer_encoder_2    │ ?                      │       \u001b[38;5;34m264,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mCustomTransformerEncoder\u001b[0m)      │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_6      │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sampling_6 (\u001b[38;5;33mSampling\u001b[0m)           │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m33664\u001b[0m)             │     \u001b[38;5;34m1,110,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m263\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_transformer_decoder_2    │ ?                      │       \u001b[38;5;34m264,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mCustomTransformerDecoder\u001b[0m)      │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_89 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m263\u001b[0m, \u001b[38;5;34m21\u001b[0m)           │         \u001b[38;5;34m2,709\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,654,613</span> (6.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,654,613\u001b[0m (6.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,654,613</span> (6.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,654,613\u001b[0m (6.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - loss: 5.3254 - val_loss: 2.2247\n",
      "Epoch 2/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - loss: 2.2528 - val_loss: 2.1317\n",
      "Epoch 3/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.1635 - val_loss: 2.1103\n",
      "Epoch 4/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.1371 - val_loss: 2.0940\n",
      "Epoch 5/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.1205 - val_loss: 2.0851\n",
      "Epoch 6/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1778s\u001b[0m 22s/step - loss: 2.1094 - val_loss: 2.0767\n",
      "Epoch 7/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 2s/step - loss: 2.1001 - val_loss: 2.0737\n",
      "Epoch 8/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - loss: 2.0951 - val_loss: 2.0739\n",
      "Epoch 9/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - loss: 2.0897 - val_loss: 2.0668\n",
      "Epoch 10/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - loss: 2.0858 - val_loss: 2.0657\n",
      "Epoch 11/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m879s\u001b[0m 11s/step - loss: 2.0848 - val_loss: 2.0679\n",
      "Epoch 12/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0794 - val_loss: 2.0639\n",
      "Epoch 13/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0793 - val_loss: 2.0635\n",
      "Epoch 14/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0772 - val_loss: 2.0618\n",
      "Epoch 15/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0773 - val_loss: 2.0619\n",
      "Epoch 16/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0763 - val_loss: 2.0605\n",
      "Epoch 17/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - loss: 2.0716 - val_loss: 2.0630\n",
      "Epoch 18/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - loss: 2.0742 - val_loss: 2.0607\n",
      "Epoch 19/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - loss: 2.0729 - val_loss: 2.0609\n",
      "Epoch 20/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2s/step - loss: 2.0697 - val_loss: 2.0589\n",
      "Epoch 21/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - loss: 2.0685 - val_loss: 2.0585\n",
      "Epoch 22/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - loss: 2.0669 - val_loss: 2.0579\n",
      "Epoch 23/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - loss: 2.0671 - val_loss: 2.0597\n",
      "Epoch 24/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - loss: 2.0650 - val_loss: 2.0580\n",
      "Epoch 25/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 2s/step - loss: 2.0664 - val_loss: 2.0585\n",
      "Epoch 26/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - loss: 2.0662 - val_loss: 2.0571\n",
      "Epoch 27/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 2s/step - loss: 2.0676 - val_loss: 2.0573\n",
      "Epoch 28/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - loss: 2.0666 - val_loss: 2.0553\n",
      "Epoch 29/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 2s/step - loss: 2.0655 - val_loss: 2.0570\n",
      "Epoch 30/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 2s/step - loss: 2.0636 - val_loss: 2.0562\n",
      "Epoch 31/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - loss: 2.0619 - val_loss: 2.0563\n",
      "Epoch 32/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0633 - val_loss: 2.0568\n",
      "Epoch 33/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - loss: 2.0641 - val_loss: 2.0563\n",
      "Epoch 34/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0652 - val_loss: 2.0559\n",
      "Epoch 35/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 2s/step - loss: 2.0623 - val_loss: 2.0575\n",
      "Epoch 36/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0624 - val_loss: 2.0561\n",
      "Epoch 37/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - loss: 2.0657 - val_loss: 2.0561\n",
      "Epoch 38/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - loss: 2.0616 - val_loss: 2.0562\n"
     ]
    }
   ],
   "source": [
    "# ------ Training Setup ------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load pre-split data (assuming they are saved in 'kinase_data_splits.npz')\n",
    "    data = np.load('kinase_data_splits.npz')\n",
    "    X_train = data['X_train'].astype(np.float32)\n",
    "    X_val = data['X_val'].astype(np.float32)\n",
    "    X_test = data['X_test'].astype(np.float32)\n",
    "    \n",
    "    # Reshape data for transformer input: (batch, seq_length, input_dim)\n",
    "    sequence_length = 263\n",
    "    input_dim = 21\n",
    "    X_train_t = X_train.reshape(-1, sequence_length, input_dim)\n",
    "    X_val_t = X_val.reshape(-1, sequence_length, input_dim)\n",
    "    X_test_t = X_test.reshape(-1, sequence_length, input_dim)\n",
    "    \n",
    "    # Create and compile the Transformer VAE\n",
    "    transformer_vae = TransformerVAE(seq_length=sequence_length, input_dim=input_dim, latent_dim=32,\n",
    "                                      num_heads=4, intermediate_dim=128)\n",
    "    transformer_vae.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    # Build model with a dummy input to initialize layers.\n",
    "    dummy_input = np.zeros((1, sequence_length, input_dim), dtype=np.float32)\n",
    "    _ = transformer_vae(dummy_input)\n",
    "    transformer_vae.summary()\n",
    "    \n",
    "    # Define callbacks.\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ModelCheckpoint('best_transformer_vae.keras', monitor='val_loss', save_best_only=True)\n",
    "        ]\n",
    "\n",
    "    \n",
    "    # Train the model.\n",
    "    history = transformer_vae.fit(\n",
    "        X_train_t, X_train_t,\n",
    "        validation_data=(X_val_t, X_val_t),\n",
    "        epochs=100, batch_size=128,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Final model save.\n",
    "    transformer_vae.save('final_transformer_vae.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
