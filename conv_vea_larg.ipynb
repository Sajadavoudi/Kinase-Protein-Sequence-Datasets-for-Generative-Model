{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d12eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import ConvexHull\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5afe8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(input_f):\n",
    "    sequences = []\n",
    "    current_seq = \"\"\n",
    "    with open(input_f, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if current_seq:\n",
    "                    sequences.append(current_seq)\n",
    "                    current_seq = \"\"\n",
    "            else:\n",
    "                current_seq += line\n",
    "        if current_seq:\n",
    "            sequences.append(current_seq)\n",
    "    return sequences\n",
    "\n",
    "def select_random_sequences(sequences, num_samples=10000):\n",
    "    if len(sequences) < num_samples :\n",
    "        raise ValueError(\"The number of requested sequences exceeds the initial list size.\")\n",
    "\n",
    "    return random.sample(sequences, num_samples)\n",
    "\n",
    "\n",
    "def encode_sequences_one_hot_with_gap(sequences, max_length=None) :\n",
    "\n",
    "    amino_acids = '-ACDEFGHIKLMNPQRSTVWY'\n",
    "    aa_to_idx = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "    valid_sequences = [seq for seq in sequences if all(aa in aa_to_idx for aa in seq)]\n",
    "\n",
    "    if not valid_sequences :  # Return empty array if no valid sequences remain\n",
    "        return np.array([])\n",
    "\n",
    "    # Set maximum length\n",
    "    if max_length is None :\n",
    "        max_length = max(len(seq) for seq in valid_sequences)\n",
    "\n",
    "    # Initialize the output matrix with zeros\n",
    "    M = len(valid_sequences)\n",
    "    L = max_length\n",
    "    encoded_matrix = np.zeros((M, L, len(amino_acids)), dtype=np.float32)\n",
    "\n",
    "    # Encode each sequence\n",
    "    for i, seq in enumerate(valid_sequences) :\n",
    "        for j, aa in enumerate(seq[:max_length]) :  # Truncate sequences longer than max_length\n",
    "            encoded_matrix[i, j, aa_to_idx[aa]] = 1.0  # One-hot encode valid amino acids and gaps\n",
    "    return encoded_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84540690",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list = read_fasta('PF00069_noinserts_gaps_noduplicates.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d2288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_batch_seq_list = select_random_sequences(seq_list, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85008c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199154, 5523)\n"
     ]
    }
   ],
   "source": [
    "encoded_matrix = encode_sequences_one_hot_with_gap(small_batch_seq_list, max_length=None)\n",
    "M, L, A = encoded_matrix.shape  # M: number of sequences, L: sequence length, A: alphabet size (21)\n",
    "flattened_matrix = encoded_matrix.reshape(M, L*A)  # Shape: (M, L * 21)\n",
    "print(flattened_matrix.shape)\n",
    "# Save the flattened matrix in a compressed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e841f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (139402, 5523)\n",
      "Validation shape: (29878, 5523)\n",
      "Test shape: (29874, 5523)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# First, split into training+validation and test (e.g., 85% for training+validation, 15% for test)\n",
    "X_train_val, X_test = train_test_split(flattened_matrix, test_size=0.15, random_state=42)\n",
    "\n",
    "# Now split training+validation into training and validation (e.g., 82.35% training, 17.65% validation)\n",
    "# so that overall it is (70% train, 15% val, 15% test)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size=0.1765, random_state=42)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae437c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Sampling Layer ------\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Reparameterization trick layer.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config()\n",
    "\n",
    "# ------ Convolutional VAE Model ------\n",
    "class ConvVAE(Model):\n",
    "    def __init__(self, sequence_length=263, input_dim=21, latent_dim=32, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "          sequence_length: Number of amino acids per sequence (e.g., 263).\n",
    "          input_dim: One-hot encoded dimension (e.g., 21).\n",
    "          latent_dim: Dimension of the latent space (e.g., 32).\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # ------ Encoder ------\n",
    "        # Input shape: (batch, 263, 21)\n",
    "        self.conv1 = layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        self.conv2 = layers.Conv1D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.conv3 = layers.Conv1D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        # Compute the reduced sequence length using ceiling division.\n",
    "        # After two conv layers with stride 2, reduced_seq_length = ceil(ceil(sequence_length/2)/2)\n",
    "        self.reduced_seq_length = int(np.ceil(sequence_length / 2.0 / 2.0))  # For 263, expected to be 66.\n",
    "        self.intermediate_dim = 128 * self.reduced_seq_length  # (128 * 66 = 8448)\n",
    "        \n",
    "        # Latent variable Dense layers.\n",
    "        self.dense_z_mean = layers.Dense(latent_dim)\n",
    "        self.dense_z_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "        \n",
    "        # ------ Decoder ------\n",
    "        # Project latent vector back to flattened conv feature map.\n",
    "        self.dense_decoder = layers.Dense(self.intermediate_dim, activation='relu')\n",
    "        # Reshape to (reduced_seq_length, 128)\n",
    "        self.reshape_decoder = layers.Reshape((self.reduced_seq_length, 128))\n",
    "        \n",
    "        # Upsampling and convolution to recover sequence length.\n",
    "        self.upsample1 = layers.UpSampling1D(size=2)\n",
    "        self.conv_dec1 = layers.Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')\n",
    "        self.upsample2 = layers.UpSampling1D(size=2)\n",
    "        self.conv_dec2 = layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')\n",
    "        # Final reconstruction layer: output probabilities over 21 classes.\n",
    "        self.conv_dec3 = layers.Conv1D(filters=input_dim, kernel_size=3, padding='same', activation='softmax')\n",
    "        # Crop one extra time step if the output sequence length is 264 instead of 263.\n",
    "        self.crop = layers.Cropping1D(cropping=(0, 1))\n",
    "    \n",
    "    def encode(self, inputs, training=False):\n",
    "        # Encoder pathway.\n",
    "        x = self.conv1(inputs)                  # (batch, 263, 32)\n",
    "        x = self.conv2(x)                       # (batch, ~132, 64)\n",
    "        x = self.conv3(x)                       # (batch, ~66, 128) – expect about 66 timesteps.\n",
    "        x = self.flatten(x)                     # (batch, intermediate_dim)\n",
    "        z_mean = self.dense_z_mean(x)\n",
    "        z_log_var = self.dense_z_log_var(x)\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z\n",
    "    \n",
    "    def decode(self, z, training=False):\n",
    "        x = self.dense_decoder(z)               # (batch, intermediate_dim)\n",
    "        x = self.reshape_decoder(x)             # (batch, reduced_seq_length, 128)\n",
    "        x = self.upsample1(x)                   # (batch, reduced_seq_length*2, 128)\n",
    "        x = self.conv_dec1(x)                   # (batch, new_length, 64)\n",
    "        x = self.upsample2(x)                   # (batch, reduced_seq_length*4, 64) -> likely 264 timesteps\n",
    "        x = self.conv_dec2(x)                   # (batch, 264, 32)\n",
    "        x = self.conv_dec3(x)                   # (batch, 264, 21)\n",
    "        reconstruction = self.crop(x)           # Crop to (batch, 263, 21)\n",
    "        return reconstruction\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encode(inputs, training=training)\n",
    "        reconstruction = self.decode(z, training=training)\n",
    "        # Compute KL divergence loss.\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "        )\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstruction\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ConvVAE, self).get_config()\n",
    "        config.update({\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'input_dim': self.input_dim,\n",
    "            'latent_dim': self.latent_dim\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f81378a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"conv_vae\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"conv_vae\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">263</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8448</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">270,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">270,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8448</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">278,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,037</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cropping1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cropping1D</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">263</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m263\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m132\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8448\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │       \u001b[38;5;34m270,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │       \u001b[38;5;34m270,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sampling (\u001b[38;5;33mSampling\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8448\u001b[0m)              │       \u001b[38;5;34m278,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling1d (\u001b[38;5;33mUpSampling1D\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m132\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m132\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │        \u001b[38;5;34m24,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling1d_1 (\u001b[38;5;33mUpSampling1D\u001b[0m)  │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m264\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m264\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m264\u001b[0m, \u001b[38;5;34m21\u001b[0m)           │         \u001b[38;5;34m2,037\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cropping1d (\u001b[38;5;33mCropping1D\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m263\u001b[0m, \u001b[38;5;34m21\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">885,333</span> (3.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m885,333\u001b[0m (3.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">885,333</span> (3.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m885,333\u001b[0m (3.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - loss: 2.7755 - val_loss: 2.2832\n",
      "Epoch 2/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 70ms/step - loss: 2.2349 - val_loss: 2.1561\n",
      "Epoch 3/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 75ms/step - loss: 2.1432 - val_loss: 2.1167\n",
      "Epoch 4/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 84ms/step - loss: 2.1098 - val_loss: 2.0973\n",
      "Epoch 5/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 82ms/step - loss: 2.0929 - val_loss: 2.0864\n",
      "Epoch 6/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 84ms/step - loss: 2.0833 - val_loss: 2.0795\n",
      "Epoch 7/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 80ms/step - loss: 2.0762 - val_loss: 2.0746\n",
      "Epoch 8/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 84ms/step - loss: 2.0712 - val_loss: 2.0710\n",
      "Epoch 9/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0685 - val_loss: 2.0681\n",
      "Epoch 10/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0655 - val_loss: 2.0657\n",
      "Epoch 11/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 83ms/step - loss: 2.0634 - val_loss: 2.0639\n",
      "Epoch 12/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 84ms/step - loss: 2.0618 - val_loss: 2.0626\n",
      "Epoch 13/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 90ms/step - loss: 2.0607 - val_loss: 2.0616\n",
      "Epoch 14/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 83ms/step - loss: 2.0599 - val_loss: 2.0608\n",
      "Epoch 15/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 82ms/step - loss: 2.0586 - val_loss: 2.0596\n",
      "Epoch 16/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0578 - val_loss: 2.0591\n",
      "Epoch 17/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0567 - val_loss: 2.0583\n",
      "Epoch 18/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 82ms/step - loss: 2.0566 - val_loss: 2.0576\n",
      "Epoch 19/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 82ms/step - loss: 2.0555 - val_loss: 2.0570\n",
      "Epoch 20/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0551 - val_loss: 2.0566\n",
      "Epoch 21/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 81ms/step - loss: 2.0552 - val_loss: 2.0563\n",
      "Epoch 22/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 84ms/step - loss: 2.0550 - val_loss: 2.0560\n",
      "Epoch 23/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0540 - val_loss: 2.0555\n",
      "Epoch 24/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 84ms/step - loss: 2.0541 - val_loss: 2.0556\n",
      "Epoch 25/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 82ms/step - loss: 2.0540 - val_loss: 2.0551\n",
      "Epoch 26/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0531 - val_loss: 2.0551\n",
      "Epoch 27/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 81ms/step - loss: 2.0527 - val_loss: 2.0547\n",
      "Epoch 28/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0534 - val_loss: 2.0549\n",
      "Epoch 29/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0522 - val_loss: 2.0544\n",
      "Epoch 30/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0522 - val_loss: 2.0542\n",
      "Epoch 31/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 84ms/step - loss: 2.0531 - val_loss: 2.0541\n",
      "Epoch 32/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 83ms/step - loss: 2.0526 - val_loss: 2.0540\n",
      "Epoch 33/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 82ms/step - loss: 2.0519 - val_loss: 2.0539\n",
      "Epoch 34/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 81ms/step - loss: 2.0517 - val_loss: 2.0540\n",
      "Epoch 35/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 93ms/step - loss: 2.0514 - val_loss: 2.0535\n",
      "Epoch 36/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 83ms/step - loss: 2.0521 - val_loss: 2.0536\n",
      "Epoch 37/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 83ms/step - loss: 2.0516 - val_loss: 2.0534\n",
      "Epoch 38/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 84ms/step - loss: 2.0511 - val_loss: 2.0536\n",
      "Epoch 39/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 83ms/step - loss: 2.0511 - val_loss: 2.0531\n",
      "Epoch 40/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 83ms/step - loss: 2.0512 - val_loss: 2.0532\n",
      "Epoch 41/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 84ms/step - loss: 2.0516 - val_loss: 2.0531\n",
      "Epoch 42/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 83ms/step - loss: 2.0520 - val_loss: 2.0528\n",
      "Epoch 43/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 83ms/step - loss: 2.0502 - val_loss: 2.0528\n",
      "Epoch 44/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 83ms/step - loss: 2.0512 - val_loss: 2.0530\n",
      "Epoch 45/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 79ms/step - loss: 2.0507 - val_loss: 2.0531\n",
      "Epoch 46/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 72ms/step - loss: 2.0510 - val_loss: 2.0528\n",
      "Epoch 47/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 72ms/step - loss: 2.0510 - val_loss: 2.0526\n",
      "Epoch 48/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 79ms/step - loss: 2.0511 - val_loss: 2.0525\n",
      "Epoch 49/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 81ms/step - loss: 2.0518 - val_loss: 2.0528\n",
      "Epoch 50/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 70ms/step - loss: 2.0511 - val_loss: 2.0524\n",
      "Epoch 51/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 70ms/step - loss: 2.0506 - val_loss: 2.0528\n",
      "Epoch 52/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 70ms/step - loss: 2.0502 - val_loss: 2.0524\n",
      "Epoch 53/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 72ms/step - loss: 2.0507 - val_loss: 2.0522\n",
      "Epoch 54/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 69ms/step - loss: 2.0506 - val_loss: 2.0524\n",
      "Epoch 55/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 70ms/step - loss: 2.0507 - val_loss: 2.0524\n",
      "Epoch 56/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 80ms/step - loss: 2.0513 - val_loss: 2.0523\n",
      "Epoch 57/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 85ms/step - loss: 2.0507 - val_loss: 2.0522\n",
      "Epoch 58/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 78ms/step - loss: 2.0495 - val_loss: 2.0526\n",
      "Epoch 59/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 79ms/step - loss: 2.0499 - val_loss: 2.0520\n",
      "Epoch 60/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 78ms/step - loss: 2.0503 - val_loss: 2.0521\n",
      "Epoch 61/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 75ms/step - loss: 2.0507 - val_loss: 2.0519\n",
      "Epoch 62/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 76ms/step - loss: 2.0500 - val_loss: 2.0522\n",
      "Epoch 63/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 75ms/step - loss: 2.0500 - val_loss: 2.0523\n",
      "Epoch 64/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 73ms/step - loss: 2.0499 - val_loss: 2.0521\n",
      "Epoch 65/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 76ms/step - loss: 2.0506 - val_loss: 2.0524\n",
      "Epoch 66/100\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 75ms/step - loss: 2.0503 - val_loss: 2.0519\n"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Reshape flattened data to (batch, sequence_length, input_dim).\n",
    "    sequence_length = 263\n",
    "    input_dim = 21\n",
    "    X_train_2D = X_train.reshape(-1, sequence_length, input_dim)\n",
    "    X_val_2D   = X_val.reshape(-1, sequence_length, input_dim)\n",
    "    \n",
    "    # Instantiate and compile the ConvVAE.\n",
    "    conv_vae = ConvVAE(sequence_length=sequence_length, input_dim=input_dim, latent_dim=32)\n",
    "    conv_vae.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='categorical_crossentropy')\n",
    "    \n",
    "    # Build model with a dummy input to initialize layers.\n",
    "    dummy_input = np.zeros((1, sequence_length, input_dim), dtype=np.float32)\n",
    "    _ = conv_vae(dummy_input)\n",
    "    conv_vae.summary()\n",
    "    \n",
    "    # Define callbacks.\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint('best_conv_vae.keras', monitor='val_loss', save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    # Train the ConvVAE model.\n",
    "    history = conv_vae.fit(\n",
    "        X_train_2D, X_train_2D,\n",
    "        validation_data=(X_val_2D, X_val_2D),\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Save final model in native Keras format.\n",
    "    conv_vae.save('final_conv_vae.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
